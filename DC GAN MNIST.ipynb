{"cells":[{"cell_type":"markdown","metadata":{"id":"xbRwbOCRXoNZ"},"source":["# **Deep Convolutional GANs**"]},{"cell_type":"markdown","metadata":{"id":"w7MXyBJsYWiq"},"source":["When it comes to **generative adversarial networks (GANs),** the advent of **deep convolutional GANs** marked **the onset of a transformative era** in the field of **generative modeling and data synthesis** using **neural networks**. This innovation significantly improved the **training process of GANs**, which had previously been **notoriously challenging** and **susceptible to drastic alterations** in model outcomes with **even minor adjustments**. Consequently, the development of an **optimal structure** for **deep convolutional GANs** became a **pivotal breakthrough**, albeit a **demanding endeavor.**\n","\n","**Deep convolutional GANs, or DCGANs,** while not without their imperfections, represent a **substantial leap forward** in the **generative industry**. **DCGANs** are fundamentally rooted in **the core GAN concept** of pitting a **generator** against a **discriminator** in a **perpetual contest**. The generator strives to produce **increasingly realistic synthetic images**, while the discriminator endeavors to **distinguish between real and synthetic images**. Though this process may appear **straightforward**, it is **inherently intricate**, fraught with **challenges such as mode collapse**, the **forgetting problem**, and **various others**.\n","\n","Nevertheless, **DCGANs exhibit greater stability compared to their predecessors.** The most **significant advancement** within **deep convolutional generative adversarial networks** is the **integration of convolutional neural networks**, hence the name **\"deep convolutional.\"** Both the **generator and discriminator comprise convolutional layers**, enabling **more effective image mapping compared to the use of dense layers**, which exhibited suboptimal performance in this regard.\n","\n","In summary, the advent of **deep convolutional GANs** has significantly improved the **landscape of generative modeling** by addressing **critical training issues and introducing convolutional network architecture,** **ultimately enhancing the overall quality and stability of generated data.**"]},{"cell_type":"markdown","metadata":{"id":"7YOMeJ2FYy2W"},"source":["# **Setting Up the Environment**"]},{"cell_type":"markdown","metadata":{"id":"qpf6bK5aY2Hy"},"source":["To create a **DCGAN**, we need to **import several essential libraries and functions** that are **instrumental in building the DCGAN**. In this section, **our primary focus** will be on **importing these critical components.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.049480Z","iopub.status.busy":"2023-11-08T02:38:57.049109Z","iopub.status.idle":"2023-11-08T02:38:57.054897Z","shell.execute_reply":"2023-11-08T02:38:57.053948Z","shell.execute_reply.started":"2023-11-08T02:38:57.049453Z"},"id":"WsLzK9FeXeqA","trusted":true},"outputs":[],"source":["# Model Building\n","import os\n","import torch\n","import numpy as np\n","from torch import nn\n","\n","# Dataset\n","from torchvision.datasets import MNIST\n","from torchvision import transforms\n","from torch.utils.data import DataLoader\n","\n","# Visualizations\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.060868Z","iopub.status.busy":"2023-11-08T02:38:57.060380Z","iopub.status.idle":"2023-11-08T02:38:57.067169Z","shell.execute_reply":"2023-11-08T02:38:57.066288Z","shell.execute_reply.started":"2023-11-08T02:38:57.060838Z"},"id":"JSZdusPaZXvA","trusted":true},"outputs":[],"source":["# Set Random Seed\n","torch.manual_seed(42)\n","\n","# Constants\n","Z_DIMS = 32\n","H_DIMS = 64\n","N_CHANNELS = 1               # We want to generate a black and white image.\n","DEVICE = \"cuda\"               # Make sure to enable gpu.\n","IMG_DIMS = 28                # Size of the image\n","LEARNING_RATE = 2e-4         # Learning rate of the Networks\n","\n","# Additional optimizer parameters.\n","beta_1 = 0.5\n","beta_2 = 0.999"]},{"cell_type":"markdown","metadata":{"id":"iOEKhLlCZme8"},"source":["# **Generator Architecture**"]},{"cell_type":"markdown","metadata":{"id":"Au6eFUICZqOI"},"source":["At the **heart of the DCGAN**, we find the **generator architecture**. It **comprises a sequence of transposed convolutional layers** designed to take a **random noise vector** as **input and transform it into an image**.\n","\n","The parameters related to this **noise vector include its dimension** and the **desired size of the output image**. These **parameters are independent**, with the **image size contingent on our end goal**, while the **noise vector's dimension impacts the generator's learning process**.\n","\n","In essence, the **generator architecture** is a **model consisting of a series of consecutive transposed convolutional layers,** supplemented by **additional activation and batch normalization layers to enhance stability.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.073529Z","iopub.status.busy":"2023-11-08T02:38:57.073278Z","iopub.status.idle":"2023-11-08T02:38:57.084971Z","shell.execute_reply":"2023-11-08T02:38:57.084067Z","shell.execute_reply.started":"2023-11-08T02:38:57.073507Z"},"id":"XCoqZCrtZkwI","trusted":true},"outputs":[],"source":["class Generator(nn.Module):\n","    \"\"\"\n","    Generator Class for a Deep Convolutional Generative Adversarial Network (DCGAN).\n","\n","    Args:\n","        z_dim (int): Dimension of the input noise vector (default is Z_DIMS).\n","        hidden_dims (int): Dimension of the hidden layers (default is H_DIMS).\n","        image_channels (int): Number of channels in the output image (default is N_CHANNELS).\n","\n","    Attributes:\n","        z_dim (int): Dimension of the input noise vector.\n","        gen (nn.Sequential): A sequence of layers defining the generator architecture.\n","\n","    Methods:\n","        gen_block(in_dims, out_dims, kernel_size=4, stride=2, output_layer=False):\n","            Defines a generator block with convolution, batch normalization, and activation layers.\n","        forward(noise):\n","            Performs forward pass through the generator network.\n","\n","    \"\"\"\n","\n","    def __init__(self, z_dim: int = Z_DIMS, hidden_dims: int = H_DIMS, image_channels: int = N_CHANNELS) -> None:\n","        \"\"\"\n","        Initialize the Generator with provided input dimensions.\n","\n","        Args:\n","            z_dim (int): Dimension of the input noise vector.\n","            hidden_dims (int): Dimension of the hidden layers.\n","            image_channels (int): Number of channels in the output image.\n","        \"\"\"\n","        super(Generator, self).__init__()\n","\n","        self.z_dim = z_dim\n","        self.gen = nn.Sequential(\n","            self.gen_block(z_dim, hidden_dims * 4, kernel_size=3),\n","            self.gen_block(hidden_dims * 4, hidden_dims * 2, stride=1),\n","            self.gen_block(hidden_dims * 2, hidden_dims, kernel_size=3),\n","            self.gen_block(hidden_dims, image_channels, output_layer=True)\n","        )\n","\n","    def gen_block(self, in_dims: int, out_dims: int, kernel_size: int = 4, stride: int = 2, output_layer: bool = False):\n","        \"\"\"\n","        Define a generator block with convolution, batch normalization, and activation layers.\n","\n","        Args:\n","            in_dims (int): Number of input channels.\n","            out_dims (int): Number of output channels.\n","            kernel_size (int): Size of the convolutional kernel (default is 4).\n","            stride (int): Stride for convolution (default is 2).\n","            output_layer (bool): Whether it's the final output layer (default is False).\n","\n","        Returns:\n","            nn.Sequential: A sequence of convolutional layers with appropriate activation functions.\n","\n","        \"\"\"\n","        if not output_layer:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(in_dims, out_dims, kernel_size, stride),\n","                nn.BatchNorm2d(out_dims),\n","                nn.LeakyReLU()\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.ConvTranspose2d(in_dims, out_dims, kernel_size, stride),\n","                nn.Tanh()\n","            )\n","\n","    def forward(self, noise):\n","        \"\"\"\n","        Perform a forward pass through the generator network.\n","\n","        Args:\n","            noise (torch.Tensor): Input noise tensor to generate images.\n","\n","        Returns:\n","            torch.Tensor: Generated images.\n","        \"\"\"\n","        noise = noise.view(-1, self.z_dim, 1, 1)\n","        return self.gen(noise)\n"]},{"cell_type":"markdown","metadata":{"id":"fsE1ZDmSc5XS"},"source":["This serves as the **foundation of our generator**. We will utilize this component to construct the **generator network** later in the notebook when we delve into the **comprehensive model architecture**.\n","\n","However, currently, we are **missing one crucial function.** While our generator processes **noise**, we have yet to **create a function** for **generating this noise**. Let's address that now."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.086974Z","iopub.status.busy":"2023-11-08T02:38:57.086657Z","iopub.status.idle":"2023-11-08T02:38:57.099054Z","shell.execute_reply":"2023-11-08T02:38:57.098340Z","shell.execute_reply.started":"2023-11-08T02:38:57.086937Z"},"id":"VJanEMDxcnd5","trusted":true},"outputs":[],"source":["def generate_noise(samples: int, z_dim: int = Z_DIMS, device=DEVICE):\n","    \"\"\"\n","    Generate random noise for input to the generator.\n","\n","    Args:\n","        samples (int): Number of noise samples to generate.\n","        z_dim (int): Dimension of the noise vector (default is Z_DIMS).\n","        device: The device to place the generated noise tensor (default is DEVICE).\n","\n","    Returns:\n","        torch.Tensor: Random noise tensor of shape (samples, z_dim).\n","    \"\"\"\n","    return torch.randn(samples, z_dim, device=device)\n"]},{"cell_type":"markdown","metadata":{"id":"nlrfpsucdl0m"},"source":["Let's visually examine the **appearance of the generated noise**. This will help us appreciate the **challenge of creating meaningful content from a seemingly random and chaotic source**, as we aim to **synthesize an image of an object from this noise.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.100808Z","iopub.status.busy":"2023-11-08T02:38:57.100541Z","iopub.status.idle":"2023-11-08T02:38:57.274825Z","shell.execute_reply":"2023-11-08T02:38:57.273995Z","shell.execute_reply.started":"2023-11-08T02:38:57.100784Z"},"id":"rbgUEt8ZdkNf","outputId":"28e7170f-6e83-4f26-8979-216f7f81735f","trusted":true},"outputs":[],"source":["# Generating a noise of 32 by 32 pixels.\n","noise = generate_noise(32, z_dim=32, device=\"cpu\")\n","\n","# Visual the Noise Vector\n","plt.title(\"Noise Vector(s)\")\n","plt.imshow(noise, cmap='gray')\n","plt.axis('off')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"KsxGk0q4eaK3"},"source":["I'd like to clarify that when we refer to the **'noise vector,'** we are not feeding the entire **noise vector** into the **generator network**.\n","\n","Instead, we are working with a **slice or a single row** of the **noise vector**, which corresponds to **generating an image**. In this context, the **'32' on the first axis** and **'z_dim' on the second axis** represent the **number of samples and the dimensions of the noise vector, respectively.**\n","\n","---\n","\n","For the time being, let's proceed to **create a generator** and observe the **image generation capabilities** of this **untrained generator.**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.276009Z","iopub.status.busy":"2023-11-08T02:38:57.275773Z","iopub.status.idle":"2023-11-08T02:38:57.294717Z","shell.execute_reply":"2023-11-08T02:38:57.293960Z","shell.execute_reply.started":"2023-11-08T02:38:57.275987Z"},"id":"vXLoay1feL67","trusted":true},"outputs":[],"source":["# Initialize the generator\n","base_gen = Generator()\n","\n","# Generate noise vector\n","noise = generate_noise(10, device='cpu')\n","\n","# Model generated images from noise vector\n","synthetic_images = base_gen(noise)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.296953Z","iopub.status.busy":"2023-11-08T02:38:57.296663Z","iopub.status.idle":"2023-11-08T02:38:57.304638Z","shell.execute_reply":"2023-11-08T02:38:57.303862Z","shell.execute_reply.started":"2023-11-08T02:38:57.296927Z"},"id":"hswps7-cfcF9","trusted":true},"outputs":[],"source":["\n","def show_generations(generations, n_rows, n_cols, figsize=(8, 5), title=None, save_loc=None):\n","    \"\"\"\n","    Display a grid of synthetic images generated by the generator.\n","\n","    Args:\n","        generations (torch.Tensor): A tensor containing synthetic image data.\n","        n_rows (int): Number of rows in the grid.\n","        n_cols (int): Number of columns in the grid.\n","        figsize (tuple): Size of the figure (default is (8, 5)).\n","        title (str): Title for the figure (default is None).\n","        save_loc (str): File path to save the figure (default is None).\n","\n","    \"\"\"\n","    synthetic_images = generations.view(-1, IMG_DIMS, IMG_DIMS, N_CHANNELS).detach()\n","\n","    plt.figure(figsize=figsize)\n","    plt.suptitle(\"Synthetic Images\" if title is None else title)\n","\n","    for index in range(n_rows * n_cols):\n","        plt.subplot(n_rows, n_cols, index+1)\n","        plt.imshow(synthetic_images[index], cmap='gray')\n","        plt.axis('off')\n","\n","    if save_loc is not None:\n","        if not os.path.exists(os.path.dirname(save_loc)):\n","            os.makedirs(os.path.dirname(save_loc))\n","        plt.savefig(save_loc)\n","\n","    plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"szpIOgammv00"},"source":["It's beneficial that we've established this function. It will prove to be valuable in the later stages when we proceed with training the generative adversarial network."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.306266Z","iopub.status.busy":"2023-11-08T02:38:57.305873Z","iopub.status.idle":"2023-11-08T02:38:57.730928Z","shell.execute_reply":"2023-11-08T02:38:57.729576Z","shell.execute_reply.started":"2023-11-08T02:38:57.306241Z"},"id":"RIjA8h4Zh4xw","outputId":"cc2efb7d-649c-4ea0-b1fb-880d32b943ad","trusted":true},"outputs":[],"source":["show_generations(\n","    synthetic_images, 2, 5,\n","    figsize=(8, 3),\n","    title=\"Base Generator Synthetic Images\",\n","    save_loc=\"./Images/base_generations.png\"\n",")"]},{"cell_type":"markdown","metadata":{"id":"dRUtBL4amHiS"},"source":["At the moment, it's evident that the **model's generated images are not of high quality**. They appear more like **random noise patterns** rather than **meaningful objects or structures**."]},{"cell_type":"markdown","metadata":{"id":"vEUOeDkZmrTg"},"source":["# **Discriminator Architecture**"]},{"cell_type":"markdown","metadata":{"id":"I5ftpK1RnKq2"},"source":["The **discriminator network** bears **resemblance to a classifier network** used for **binary classification** tasks in **machine learning**. It comprises a **sequence of successive convolutional layers designed to downsample the input images**, which can be either **generated by the model or real images**. The aim is to reduce these images to a single vector that effectively determines their authenticity, labeling them as either **real (1) or fake (0).** This essentially transforms the problem into a **binary classification task**.\n","\n","However, it's crucial to note that, because **classifying real or fake images** is a **relatively simpler** task compared to the intricate **task of image generation**, this architecture has a **significant influence** on the **information shared** with the **generator network**. Due to the **relative ease** of the **classification task**, the **training phase** of the **GAN** still encounters **numerous challenges**."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.734450Z","iopub.status.busy":"2023-11-08T02:38:57.733481Z","iopub.status.idle":"2023-11-08T02:38:57.753222Z","shell.execute_reply":"2023-11-08T02:38:57.751941Z","shell.execute_reply.started":"2023-11-08T02:38:57.734402Z"},"id":"YDYlzGCcjO4S","trusted":true},"outputs":[],"source":["\n","class Discriminator(nn.Module):\n","    \"\"\"\n","    Discriminator Class for a Deep Convolutional Generative Adversarial Network (DCGAN).\n","\n","    Args:\n","        image_channels (int): Number of channels in the input images (default is N_CHANNELS).\n","        hidden_dims (int): Dimension of the hidden layers (default is 16).\n","\n","    Attributes:\n","        disc (nn.Sequential): A sequence of layers defining the discriminator architecture.\n","\n","    Methods:\n","        disc_block(in_dims, out_dims, kernel_size=3, strides=2, output_layer=False):\n","            Defines a discriminator block with convolution, batch normalization, and activation layers.\n","        forward(images):\n","            Performs forward pass through the discriminator network.\n","\n","    \"\"\"\n","\n","    def __init__(self, image_channels: int = N_CHANNELS, hidden_dims: int = 16):\n","        \"\"\"\n","        Initialize the Discriminator with provided input dimensions.\n","\n","        Args:\n","            image_channels (int): Number of channels in the input images.\n","            hidden_dims (int): Dimension of the hidden layers.\n","        \"\"\"\n","        super(Discriminator, self).__init__()\n","\n","        self.disc = nn.Sequential(\n","            self.disc_block(image_channels, hidden_dims),\n","            self.disc_block(hidden_dims, hidden_dims * 2),\n","            self.disc_block(hidden_dims * 2, 1, output_layer=True),\n","        )\n","\n","    def disc_block(self, in_dims: int, out_dims: int, kernel_size: int = 4, strides: int = 2, output_layer: bool = False):\n","        \"\"\"\n","        Define a discriminator block with convolution, batch normalization, and activation layers.\n","\n","        Args:\n","            in_dims (int): Number of input channels.\n","            out_dims (int): Number of output channels.\n","            kernel_size (int): Size of the convolutional kernel (default is 3).\n","            strides (int): Stride for convolution (default is 2).\n","            output_layer (bool): Whether it's the final output layer (default is False).\n","\n","        Returns:\n","            nn.Sequential: A sequence of convolutional layers with appropriate activation functions.\n","\n","        \"\"\"\n","        if not output_layer:\n","            return nn.Sequential(\n","                nn.Conv2d(in_dims, out_dims, kernel_size, strides),\n","                nn.BatchNorm2d(out_dims),\n","                nn.LeakyReLU(0.2)\n","            )\n","        else:\n","            return nn.Sequential(\n","                nn.Conv2d(in_dims, out_dims, kernel_size, strides)\n","            )\n","\n","    def forward(self, images):\n","        \"\"\"\n","        Perform a forward pass through the discriminator network.\n","\n","        Args:\n","            images (torch.Tensor): Input image tensor to classify.\n","\n","        Returns:\n","            torch.Tensor: Classification output (real or fake).\n","        \"\"\"\n","        return self.disc(images).view(-1, 1)\n"]},{"cell_type":"markdown","metadata":{"id":"wOLwSdtHpWnY"},"source":["Testing the **untrained discriminator network** at this point **wouldn't yield meaningful results**. Its responses are **more likely** to be **random rather than providing meaningful assessments**, given that it has yet to **undergo training.**"]},{"cell_type":"markdown","metadata":{"id":"fvvys7jYpiFF"},"source":["# **DC GAN Network**"]},{"cell_type":"markdown","metadata":{"id":"vV5z4vnppnGr"},"source":["Having successfully built the **individual components**, including the **generator and discriminator networks,** which form the **foundation of the Generative Adversarial Network**, we can now proceed to construct the complete **DCGAN**.\n","\n","---\n","Note : Please connect to a **GPU device**, if using **CPU** please set the **DEVICE** constant to **\"cpu\"**."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.756667Z","iopub.status.busy":"2023-11-08T02:38:57.755689Z","iopub.status.idle":"2023-11-08T02:38:57.784628Z","shell.execute_reply":"2023-11-08T02:38:57.783922Z","shell.execute_reply.started":"2023-11-08T02:38:57.756608Z"},"id":"1yq9VTymlcZY","outputId":"34aec55d-4ce4-4782-c0da-7d9c7bed5d4a","trusted":true},"outputs":[],"source":["# Initialize the generator and discriminator.\n","generator = Generator().to(DEVICE)\n","discriminator = Discriminator().to(DEVICE)\n","\n","# Initialize the optimizers, respectively.\n","gen_opt = torch.optim.Adam(generator.parameters(), lr = LEARNING_RATE, betas=(beta_1, beta_2))\n","disc_opt = torch.optim.Adam(discriminator.parameters(), lr = LEARNING_RATE, betas=(beta_1, beta_2))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.785766Z","iopub.status.busy":"2023-11-08T02:38:57.785522Z","iopub.status.idle":"2023-11-08T02:38:57.792900Z","shell.execute_reply":"2023-11-08T02:38:57.792157Z","shell.execute_reply.started":"2023-11-08T02:38:57.785744Z"},"id":"DGAtgNgqqstr","trusted":true},"outputs":[],"source":["# Initializing the weights, so that they belong to a normal distribution.\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","    if isinstance(m, nn.BatchNorm2d):\n","        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n","        torch.nn.init.constant_(m.bias, 0)\n","\n","generator = generator.apply(weights_init)\n","discriminator = discriminator.apply(weights_init)"]},{"cell_type":"markdown","metadata":{},"source":["Having prepared **the generator and the discriminator blocks** with their **initialized weights**, it's now time to **tackle some critical tasks**. Firstly, we need to establish **the criteria** that will guide **our training process**. Additionally, we haven't **loaded the dataset yet**, so we'll also **address the data loading step**."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.796050Z","iopub.status.busy":"2023-11-08T02:38:57.795565Z","iopub.status.idle":"2023-11-08T02:38:57.803483Z","shell.execute_reply":"2023-11-08T02:38:57.802671Z","shell.execute_reply.started":"2023-11-08T02:38:57.796026Z"},"trusted":true},"outputs":[],"source":["BATCH_SIZE = 64                                     # Batch size also affected the training process.\n","criterion = nn.BCEWithLogitsLoss()                  # You might prefer to call it \"loss function\"."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:38:57.804777Z","iopub.status.busy":"2023-11-08T02:38:57.804476Z","iopub.status.idle":"2023-11-08T02:38:57.882082Z","shell.execute_reply":"2023-11-08T02:38:57.881150Z","shell.execute_reply.started":"2023-11-08T02:38:57.804754Z"},"trusted":true},"outputs":[],"source":["# Initialize the transformations.\n","transform = transforms.Compose([\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,)),\n","])\n","\n","# Initialize the data loader.\n","dataloader = DataLoader(\n","    MNIST('.', download = True, transform = transform),\n","    batch_size = BATCH_SIZE,\n","    shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["Finally, we can proceed to create the training loop."]},{"cell_type":"markdown","metadata":{},"source":["# **GAN Training Process**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-08T02:42:29.369372Z","iopub.status.busy":"2023-11-08T02:42:29.368758Z","iopub.status.idle":"2023-11-08T02:42:47.031895Z","shell.execute_reply":"2023-11-08T02:42:47.030398Z","shell.execute_reply.started":"2023-11-08T02:42:29.369341Z"},"trusted":true},"outputs":[],"source":["# Initializing some constants/variables\n","EPOCHS = 50\n","mean_gen_losses = []\n","mean_disc_losses = []\n","\n","# Starting the training loop\n","for epoch in range(EPOCHS):\n","    \n","    # Maintaining the loss per step\n","    gen_loss_per_step = []\n","    disc_loss_per_step = []\n","    \n","    # Steps inside the epochs.\n","    for real, _ in tqdm(dataloader):\n","        \n","        # Collect to the current batch size.\n","        curr_batch_size = len(real)\n","        real = real.to(DEVICE)\n","        \n","        ## Training the Discriminator\n","        disc_opt.zero_grad()\n","        \n","        # Discriminator on the generated images.\n","        noise_samples = generate_noise(samples = curr_batch_size)\n","        synthetic_images = generator(noise_samples)\n","        dics_syn_preds = discriminator(synthetic_images)\n","        \n","        # Discriminator on the real images.\n","        dics_real_preds = discriminator(real)\n","        \n","        # Average discriminator loss\n","        disc_syn_loss = criterion(dics_syn_preds, torch.zeros_like(dics_syn_preds))\n","        disc_real_loss = criterion(dics_real_preds, torch.ones_like(dics_real_preds))\n","        discriminator_loss = (disc_syn_loss + disc_real_loss) / 2\n","        disc_loss_per_step.append(discriminator_loss)\n","        \n","        discriminator_loss.backward(retain_graph=True)\n","        disc_opt.step()\n","        \n","        ## Training the Generator\n","        gen_opt.zero_grad()\n","        \n","        noise_samples = generate_noise(samples = curr_batch_size)\n","        synthetic_images = generator(noise_samples)\n","        dics_syn_preds = discriminator(synthetic_images)\n","        \n","        generator_loss = criterion(dics_syn_preds, torch.ones_like(dics_syn_preds))\n","        gen_loss_per_step.append(generator_loss)\n","        generator_loss.backward()\n","        gen_opt.step()\n","        \n","    # Maintaining the loss per epoch\n","    mean_disc_losses.append(np.mean(disc_loss_per_step))\n","    mean_gen_losses.append(np.mean(gen_loss_per_step))    \n","    \n","    # Visualized generations after each epoch.\n","    noise_vector = generate_noise(10)\n","    generations = generator(noise_vector)\n","    show_generations(\n","        generations, 2, 5,\n","        title = f\"Generations at Epoch:{epoch+1}\",\n","        save_loc = f\"./Images/training_gen_{epoch + 1}.png\"\n","    )"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
